


---

# Ethical, Social, and Political Issues Raised by Information Systems

## Overview

Information technology is introducing changes for which laws and rules of acceptable conduct have not yet been developed. Increasing computing power, storage, and networking capabilities—including the Internet—expand the reach of individual and organizational actions and magnify their impacts. The ease and anonymity with which information is now communicated, copied, and manipulated in online environments pose new challenges to the protection of privacy and intellectual property.

## Five Moral Dimensions of the Information Age

The major ethical, social, and political issues raised by information systems include the following moral dimensions:

### Information Rights and Obligations
**What information rights do individuals and organizations possess with respect to information about themselves?** What can they protect? What obligations do individuals and organizations have concerning this information?

Privacy is the claim of individuals to be left alone, free from surveillance or interference from other individuals or organizations, including the state.

### Property Rights and Obligations
**How will traditional intellectual property rights be protected in a digital society** in which tracing and accounting for ownership are difficult and ignoring such property rights is so easy?

Intellectual property is considered to be intangible property created by individuals or corporations. Information technology has made it difficult to protect intellectual property because computerized information can be so easily copied or distributed on networks.

### Accountability and Control
**Who can and will be held accountable and liable for the harm done** to individual and collective information and property rights?

Accountability is a feature of systems and social institutions and means mechanisms are in place to determine who took responsible action, and who is responsible.

### System Quality
**What standards of data and system quality should we demand** to protect individual rights and the safety of society?

Three principal sources of poor system performance are (1) software bugs and errors, (2) hardware or facility failures caused by natural or other causes, and (3) poor input data quality.

### Quality of Life
**What values should be preserved in an information-and knowledge-based society?** Which institutions should we protect from violation? Which cultural values and practices are supported by the new information technology?

## Key Technology Trends That Raise Ethical Issues

### Doubling of Computer Power
The doubling of computer power every 18 months has made it possible for more organizations to depend on information systems for their core production processes. This has increased vulnerability to system errors and poor data quality.

### Rapidly Declining Data Storage Costs
Advances in data storage techniques and declining storage costs have been responsible for increases in databases of individual employees, customers and suppliers. These advances have made routine violations to individual privacy both cheap and effective.

### Advances in Data Analysis Techniques

**Profiling**
Profiling involves combining data from multiple sources to create dossiers of detailed information on individuals.

**Non-Obvious Relationship Awareness (NORA)**
Non-obvious relationship awareness (NORA) is a more powerful profiling capability technology that can take information about people from many disparate sources, such as employment applications, telephone records, customer listings, and "wanted" lists, and correlate relationships to find obscure hidden connections that might help identify criminals or terrorists. It includes tracking of individual cell phones.

## Basic Concepts of Ethical Analysis

### Responsibility
Responsibility means that you accept the potential costs, duties, and obligations for the decisions you make.

### Accountability
Accountability means mechanisms are in place for identifying who took responsible actions and who are the responsible parties.

### Liability
Liability is a feature of political systems in which a body of laws permits individuals and firms to recover damages to them by other actors, systems or organizations.

### Due Process
Due process is a related feature of law-governed societies and is a process in which laws are well known and understood and there is an ability to appeal to higher authorities to ensure that the laws are applied correctly.

## Ethical Principles

Organizations can apply several ethical principles to guide decisions:

- **Golden Rule** - Treat others as you would want to be treated
- **Immanuel Kant's Categorical Imperative** - Act only in ways you would want to become universal law
- **Descartes Rule of Change** - Assume the consequences of your actions will be permanent
- **Utilitarian Principle** - Choose actions that produce the greatest good for the greatest number
- **Risk-aversion Principle** - Choose the option that minimizes potential harm
- **Ethical "no free lunch" Rule** - Assume all actions have consequences

## Privacy and Information Rights

### Fair Information Practices (FIP)
Most American and European privacy law is based on a regime called Fair Information Practices (FIP) first set forth in a report written in 1973 by a federal government advisory committee.

### European Directive on Data Protection
In Europe, privacy protection is much more stringent than in the United States. Unlike the United States, European countries do not allow businesses to use personally identifiable information without consumers' prior consent. Informed consent can be defined as consent given with knowledge of all the facts needed to make a rational decision.

### Internet Challenges to Privacy

**Cookies**
Cookies are small text files deposite

---

# Key Technology Trends That Raise Ethical Issues

## Overview

Information technology has heightened ethical concerns, taxed existing social arrangements, and made some laws obsolete or severely crippled. There are four key technological trends responsible for these ethical stresses.

## 1. Doubling of Computing Power Every 18 Months

The doubling of computing power every 18 months has made it possible for most organizations to use information systems for their core production processes. As a result, our dependence on systems and our vulnerability to system errors and poor data quality have increased. Social rules and laws have not yet adjusted to this dependence. Standards for ensuring the accuracy and reliability of information systems are not universally accepted or enforced.

**Ethical Impact:**
- Organizations depend critically on systems that may fail
- Poor data quality can have serious consequences
- Legal frameworks lag behind technological capabilities

## 2. Rapidly Declining Data Storage Costs

Advances in data storage techniques and rapidly declining storage costs have been responsible for the multiplying databases on individuals—employees, customers, and potential customers—maintained by private and public organizations. These advances in data storage have made the routine violation of individual privacy both cheap and effective. Already massive data storage systems are cheap enough for regional and even local retailing firms to use in identifying customers.

**Ethical Impact:**
- Personal information is easily collected and stored
- Privacy violations become economically feasible
- Even small organizations can maintain detailed customer profiles

## 3. Advances in Data Analysis Techniques

Advances in data analysis techniques for large pools of data heighten ethical concerns because companies and government agencies are able to find out much detailed personal information about individuals. With contemporary data management tools, companies can assemble and combine the myriad pieces of information about individuals stored on computers much more easily than in the past.

### Profiling Example
Hundreds of websites allow DoubleClick (an Internet advertising broker) to track the activities of their visitors in exchange for revenue from advertisements based on visitor information DoubleClick gathers. DoubleClick uses this information to create a profile of each online visitor, adding more detail to the profile as the visitor accesses an associated DoubleClick site. Over time, DoubleClick can create a detailed dossier of a person's spending and computing habits on the Web that can be sold to companies to help them target their Web ads more precisely.

### Non-Obvious Relationship Awareness (NORA)
A new data analysis technology called **non-obvious relationship awareness (NORA)** has given both the government and the private sector even more powerful profiling capabilities. NORA can take information about people from many disparate sources, such as employment applications, telephone records, customer listings, and "wanted" lists, and correlate relationships to find obscure hidden connections that might help identify criminals or terrorists.

**NORA Applications:**
- NORA technology scans data and extracts information as the data are being generated so that it could, for example, instantly discover a man at an airline ticket counter who shares a phone number with a known terrorist before that person boards an airplane
- It might discover that an applicant for a job at a casino shares a telephone number with a known criminal and issue an alert to the hiring manager
- The technology is considered a valuable tool for homeland security but does have privacy implications because it can provide such a detailed picture of the activities and associations of a single individual

**Ethical Impact:**
- Detailed personal profiles can be created from disparate sources
- Hidden connections between individuals can be discovered
- Powerful surveillance capabilities raise privacy concerns

## 4. Advances in Networking, Including the Internet

Advances in networking, including the Internet, promise to reduce greatly the costs of moving and accessing large quantities of data and open the possibility of mining large pools of data remotely using small desktop machines, permitting an invasion of privacy on a scale and with a precision heretofore unimaginable. If computing and networking technologies continue to advance at the same pace as in the past, by 2023 large organizations will be able to devote the equivalent of a contemporary desktop personal computer to monitoring each of the 350 million individuals who will then be living in the United States.

**Ethical Impact:**
- Remote data access enables massive-scale privacy invasions
- Individual monitoring becomes technically and economically feasible
- Privacy protection becomes increasingly difficult

## Summary

These four technological trends—computing power, data storage, data analysis, and networking—have created unprecedented capabilities for collecting, storing, analyzing, and accessing personal information, raising significant ethical concerns about privacy, surveillance, and individual rights.


---

# Responsibility, Accountability, and Liability

## Overview

Three key concepts form the foundation for understanding ethical obligations in information systems: responsibility, accountability, and liability. These concepts are interconnected and essential for addressing ethical and social issues raised by information technology.

## Responsibility

**Responsibility** means that you accept the potential costs, duties, and obligations for the decisions you make. Responsibility is an ethical concept that refers to the fact that individuals and groups have morally based obligations and duties to others and to larger ethical and moral codes, standards and traditions.

### Responsibility in Information Systems

Responsibility is a social construct representing the ascription of an object to a subject. In the context of information systems, responsibility involves understanding how decisions made by individuals, organizations, and systems affect others.

**Key aspects of responsibility:**
- Accepting consequences of actions and decisions
- Understanding moral obligations to others
- Recognizing duties to larger ethical codes and standards
- Considering impacts on individuals and society

### Shared Responsibility

While all employees of an organization are responsible for issues like cybersecurity, responsibility and accountability are not always equitably shared. In the corporate world, not every actor is blame-worthy, especially if the actor's autonomy is limited by structure, process, or circumstance. However, lack of autonomy is not an excuse for avoiding accountability entirely.

Responsibility is viewed as greater than the individual; as a shared relationship based on core virtues such as awareness and integrity determined by roles.

## Accountability

**Accountability** is a feature of systems and social institutions and means mechanisms are in place to determine who took responsible action, and who is responsible. Accountability refers to the structures and institutions that establish a link between object and subject, making it a necessary condition of successful responsibility ascriptions.

### Accountability Mechanisms

Accountability requires that:
- Clear structures exist to identify responsible parties
- Institutions establish links between actions and actors
- Mechanisms exist to trace decisions and their consequences
- Transparency exists in how responsibility is assigned

### Accountability in Cybersecurity

While all employees are responsible for cybersecurity, accountability often falls on leadership. Classic examples are the EU General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA), where emerging modern laws increase legal liability risk. Information security governance is the responsibility of the board of directors and senior executives.

### Pathological Accountability

A challenge in information systems is **pathological accountability**, where accountability becomes reified and solidified and in effect goes counter to the social aim of responsibility. This occurs when accountability structures become rigid and disconnected from their original purpose of ensuring ethical behavior.

## Liability

**Liability** is a feature of political systems in which a body of laws permits individuals and firms to recover damages to them by other actors, systems or organizations. Liability provides legal recourse when harm occurs.

### Liability in Information Systems

Determining liability and responsibility for software or hardware defects that can cause data breaches or other negative consequences is an ethical concern. Organizations must establish clear policies about who bears responsibility when systems fail or cause harm.

### Legal Frameworks

Legal frameworks establish liability through:
- Laws permitting recovery of damages
- Regulations defining responsibility for system failures
- Standards for system security and data protection
- Requirements for disclosure and remediation

## The Three-Part Framework

**Responsibility, accountability, and liability are three interconnected concepts:**

- **Imputability** - The ability to attribute an action to an actor
- **Accountability** - Structures and mechanisms to establish responsibility
- **Liability** - Legal consequences and remedies for harm

## Due Process

**Due process** is a related feature of law-governed societies and is a process in which laws are well known and understood and there is an ability to appeal to higher authorities to ensure that the laws are applied correctly.

Due process ensures that:
- Laws are clearly communicated
- Individuals understand their obligations
- Appeal mechanisms exist for disputes
- Fair procedures are followed

## Challenges in Information Systems

### Complexity and Multiple Actors

Complex networks of causes and decisions, typical of situations in which many hands operate, may obscure accountability. When multiple people contribute to system decisions, determining who is responsible becomes difficult.

### Automation and Delegation

Certain prevalent design features, such as anthropomorphizing a system, delegating decision making to it, and delegating instruction to it diminish a user's sense of agency and responsibility. When responsibility is delegated to automated systems, it becomes unclear who bears accountability.

### Moral Responsibility of Computers

It has even been argued that intelligent computer systems can bear moral responsibility themselves. This raises questions about how responsibility should be assigned when autonomous systems make decisions.

## Professional Codes of Conduct

Professional organizations establish codes of ethics to guide responsibility and accountability. The ACM Code of Ethics and Professional Conduct serves as the conscience of the computing profession. The Code expresses the values and aspirations of computing professionals and serves as a guide for ethical decision-making.

## Summary

Responsibility, accountability, and liability work together to create frameworks for ethical behavior in information systems:

- **Responsibility** establishes moral obligations
- **Accountability** creates mechanisms to identify responsible parties
- **Liability** provides legal consequences and remedies

Together, these concepts ensure that individuals and organizations can be held responsible for their actions and their impacts on other.


# Ethical Analysis

## Overview

Ethical analysis is the process of applying ethical principles and frameworks to evaluate decisions and actions, particularly in the context of information systems. It provides a structured approach to identifying and resolving ethical dilemmas.

## A Model for Thinking About Ethical, Social, and Political Issues

Ethical analysis involves examining issues through multiple dimensions:

### Identifying the Ethical Issue
- Recognize that an ethical problem exists
- Understand the moral dimensions involved
- Identify stakeholders affected by the decision
- Clarify the values and principles at stake

### Analyzing Stakeholder Perspectives
- Consider how different groups are affected
- Understand competing interests and values
- Recognize power imbalances
- Identify vulnerable populations

### Applying Ethical Principles
- Use established ethical frameworks to evaluate options
- Consider consequences, duties, and virtues
- Balance competing values and principles
- Assess alignment with organizational values

## Candidate Ethical Principles

Organizations and individuals can apply several ethical principles to guide decisions and actions:

### The Golden Rule
**"Treat others as you would want to be treated"**

This principle emphasizes reciprocity and empathy. Apply this principle by asking: Would I want this action taken toward me or my family?

**Application in information systems:**
- Privacy decisions - Would you want your personal data collected this way?
- System design - Would you want to use a system designed this way?
- Data sharing - Would you want your information shared in this manner?

### Immanuel Kant's Categorical Imperative
**"Act only in ways that you would want to become universal law"**

This principle suggests that ethical actions should be ones that could be applied universally without contradiction. Ask: Would I want everyone to act this way?

**Application in information systems:**
- Data practices - Could this data practice be applied universally?
- System policies - Would universal application of this policy be acceptable?
- Security measures - Should all organizations implement this security approach?

### Descartes' Rule of Change
**"Assume the consequences of your actions will be permanent"**

This principle encourages considering long-term and lasting impacts of decisions. Ask: What if this action and its consequences became permanent and irreversible?

**Application in information systems:**
- Data collection - Assume collected data will exist forever
- System design - Assume design choices will be permanent
- Privacy policies - Assume policies will never change

### The Utilitarian Principle
**"Choose actions that produce the greatest good for the greatest number"**

This principle focuses on maximizing overall benefit and minimizing harm. Ask: Which option produces the best outcome for the most people?

**Application in information systems:**
- System investments - Does this benefit the most users?
- Data policies - Does this serve the majority while minimizing harm?
- Feature prioritization - Which features benefit the most people?

### The Risk Aversion Principle
**"Choose the option that minimizes potential harm"**

This principle emphasizes caution and protection against worst-case scenarios. Ask: Which option poses the least risk of serious harm?

**Application in information systems:**
- Security decisions - Which approach best protects against breaches?
- Data retention - Should we minimize data collection to reduce risk?
- System reliability - Which design is most robust and fault-tolerant?

### The Ethical "No Free Lunch" Rule
**"Assume all actions have consequences"**

This principle recognizes that every decision involves trade-offs and costs. Ask: What are the hidden costs and consequences of this action?

**Application in information systems:**
- Cloud migration - What are the full costs and consequences?
- Automation - What jobs and skills are affected?
- Data analytics - What are the privacy and social consequences?

## Ethical Analysis Process

### Step 1: Identify the Ethical Issue
- What ethical problem or dilemma exists?
- What values are in conflict?
- Who is affected by this decision?
- What are the potential harms and benefits?

### Step 2: Identify Stakeholders
- Who will be affected by the decision?
- What are their interests and concerns?
- Who has power in this situation?
- Whose voices might be overlooked?

### Step 3: Identify Options
- What are the possible courses of action?
- What are the consequences of each option?
- Are there creative alternatives?
- What constraints limit the options?

### Step 4: Apply Ethical Principles
- How does each option align with ethical principles?
- Which principles are most relevant?
- Do principles conflict?
- What does each principle suggest?

### Step 5: Make a Decision
- Which option best aligns with ethical principles?
- Can the decision be justified to stakeholders?
- What are the implementation considerations?
- How will consequences be monitored?

### Step 6: Implement and Monitor
- How will the decision be communicated?
- What mechanisms ensure accountability?
- How will outcomes be measured?
- What adjustments may be needed?

## Applying Ethical Principles to Information Systems Issues

### Privacy Decisions
When deciding what personal data to collect:
- **Golden Rule**: Would you want your data collected this way?
- **Categorical Imperative**:

# Candidate Ethical Principles and Professional Codes of Conduct

## Candidate Ethical Principles

Organizations and individuals can apply several ethical principles to guide decisions and actions in information systems:

### 1. The Golden Rule
**"Do unto others as you would have them do unto you"**

Put yourself into the place of others, and think of yourself as the object of the decision. This principle emphasizes reciprocity and empathy.

**Application:** Ask yourself, "Would I want this action taken toward me or my family?"

### 2. Immanuel Kant's Categorical Imperative
**"If an action is not right for everyone to take, it is not right for anyone"**

Ask yourself, "If everyone did this, could the organization, or society, survive?" This principle suggests that ethical actions should be ones that could be applied universally without contradiction.

**Application:** Consider whether the action could become a universal law that everyone follows.

### 3. Descartes' Rule of Change (Slippery Slope Rule)
**"If an action cannot be taken repeatedly, it is not right to take at all"**

An action may bring about a small change now that is acceptable, but if it is repeated, it would bring unacceptable changes in the long run. Ask yourself, "If I take this action, what will happen if it is taken many times over?"

**Application:** Assume the consequences of your actions will be permanent and consider long-term impacts.

### 4. The Utilitarian Principle
**"Take the action that achieves the higher or greater value"**

This principle assumes you can prioritize values in a rank order and understand the consequences of various courses of action. Ask yourself, "Which option produces the greatest good for the greatest number?"

**Application:** Choose actions that maximize overall benefit and minimize harm to the most people.

### 5. The Risk Aversion Principle
**"Take the action that produces the least harm or the least potential cost"**

Some actions have extremely high failure costs of very low probability (e.g., building a nuclear generating facility in an urban area) or extremely high failure costs of moderate probability (speeding and automobile accidents). Avoid these high-failure-cost actions; focus on reducing risk.

**Application:** Choose the option that minimizes potential harm, especially catastrophic harm.

### 6. The Ethical "No Free Lunch" Rule
**"Assume that virtually all tangible and intangible objects are owned by someone else unless there is a specific declaration otherwise"**

If something someone else has created is useful to you, it has value, and you should assume the creator wants compensation for this work. This principle recognizes that every decision involves trade-offs and costs.

**Application:** Assume all actions have consequences and all resources have value that must be respected.

## Professional Codes of Conduct

Professional codes of conduct are rules that guide the actions and behavior of members of a profession. These codes help professionals navigate ethical dilemmas and maintain standards of practice.

### Purpose of Professional Codes
- Provide ethical guidance for professional practice
- Establish standards of behavior for the profession
- Protect the public interest
- Maintain professional reputation and trust
- Guide decision-making in complex situations
- Define professional responsibilities

### Key Professional Codes in Information Systems

#### ACM Code of Ethics and Professional Conduct

The **Association for Computing Machinery (ACM)** has developed a comprehensive code of ethics for computing professionals. The ACM Code of Ethics and Professional Conduct serves as the conscience of the computing profession.

**General Moral Imperatives:**
1. Contribute to society and to human well-being, acknowledging that all people are stakeholders in computing
2. Avoid harm
3. Be honest and trustworthy
4. Be fair and take action not to discriminate
5. Respect the work required to produce new ideas, inventions, creative works, and computing artifacts
6. Respect privacy
7. Honor confidentiality

**Professional Responsibilities:**
1. Strive to achieve high quality in both the processes and products of professional work
2. Maintain high standards of professional competence, conduct, and ethical practice
3. Know and respect existing rules pertaining to professional work
4. Accept and provide appropriate professional review
5. Give comprehensive and thorough evaluations of computer systems and their impacts, including analysis of possible risks
6. Perform work only in areas of competence
7. Foster public awareness and understanding of computing, related technologies, and their consequences
8. Access computing and communication resources only when authorized or when compelled by the public good
9. Design and implement systems that are robustly and usably secure

**Professional Leadership Principles:**
1. Ensure that the public good is the central concern during all professional computing work
2. Articulate, encourage acceptance of, and evaluate fulfillment of social responsibilities by members of the organization or group
3. Manage personnel and resources to enhance the quality of working life
4. Articulate, apply, and support policies and processes that reflect the principles of the Code
5. Create opportunities for members of the organization or group to grow as professionals
6. Use care when modifying or retiring systems
7. Recognize and take special care of systems that become integrated into the infrastructure of society

#### IEEE Code of Ethics

The **Institute of Electrical and Electronics Engineers (IEEE)** also provides ethical guidelines for technology professionals.

**Key Principles:**
- Accept responsibility in making decisions consistent with the safety, health, and welfare of the public
- Avoid real or perceived conflicts of interest whenever possible
- Be honest and realistic in stating claims or estimates based on available data
- Reject bribery in all its forms
- Improve the understanding of technology; its appropriate application, and potential consequences
- Maintain and improve technical competence
- Seek, accept, and offer honest criticism of technical work
- Treat fairly all persons and to not engage in acts of discrimination
- Avoid injuring others, their property, reputation, or employment by false or malicious action
- Assist colleagues and co-workers in their professional development

#### Other Professional Organizations

**AITP (Association of Information Technology Professionals)**
Provides standards of conduct for IT professionals focusing on:
- Professional development and competence
- Ethical use of information technology
- Responsibility to employers and clients
- Social responsibility

**ISACA (Information Systems Audit and Control Association)**
Focuses on IT governance, security, and audit professionals with emphasis on:
- Professional integrity
- Confidentiality
- Competence
- Objectivity

## Applying Professional Codes

### When to Use Professional Codes
- Facing ethical dilemmas in professional practice
- Making decisions that affect stakeholders
- Designing systems with social impacts
- Handling confidential or sensitive information
- Resolving conflicts between competing interests

### How to Apply Professional Codes
1. **Identify the ethical issue** - Recognize when a situation raises ethical concerns
2. **Consult relevant codes** - Review applicable professional codes of conduct
3. **Analyze the situation** - Consider how code principles apply to the specific case
4. **Consider stakeholders** - Identify who is affected and how
5. **Evaluate options** - Assess alternatives against code principles
6. **Make a decision** - Choose the option that best aligns with professional standards
7. **Document reasoning** - Record the ethical analysis and decision rationale
8. **Seek guidance if needed** - Consult with colleagues, mentors, or ethics committees

## Limitations of Professional Codes

While professional codes provide valuable guidance, they have limitations:

- **General principles** - Codes provide broad principles that may not address specific situations
- **Conflicting principles** - Different code provisions may conflict in particular cases
- **Interpretation required** - Applying codes requires judgment and ethical reasoning
- **Not legally binding** - Most codes are not laws, though they may inform legal standards
- **Cultural differences** - Codes may not account for all cultural perspectives
- **Evolving technology** - New technologies may raise issues not anticipated in codes

## Real-World Ethical Dilemmas

Professional codes help address common ethical dilemmas in information systems:

### Privacy vs. Security
Balancing individual privacy rights with organizational or societal security needs requires applying principles about harm avoidance, respect for persons, and public good.

### Intellectual Property
Respecting the work of others while promoting innovation requires understanding principles about ownership, fair use, and contribution to society.

### System Quality
Ensuring systems are reliable, secure, and safe requires commitment to professional competence, thoroughness, and harm avoidance.

### Whistleblowing
Deciding whether to report unethical practices requires balancing loyalty to employers with responsibility to the public and professional integrity.

## Summary

**Candidate ethical principles** provide frameworks for analyzing ethical decisions:
- Golden Rule, Categorical Imperative, and other principles offer different perspectives
- Multiple principles should be considered when making ethical decisions
- Principles may sometimes conflict, requiring careful judgment

**Professional codes of conduct** establish standards for ethical practice:
- Codes guide professional behavior and decision-making
- Major organizations like ACM and IEEE provide comprehensive ethical guidelines
- Codes emphasize responsibilities to society, employers, colleagues, and the profession
- Professional codes complement but do not replace individual ethical reasoning

Together, ethical principles and professional codes provide essential guidance for navigating the complex ethical landscape of information systems.



# Real World Ethical Dilemmas, Information Rights, and Property Rights

## Real World Ethical Dilemmas

Information systems create numerous ethical dilemmas that professionals and organizations must navigate. These dilemmas often involve conflicts between competing values, stakeholder interests, and ethical principles.

### Common Ethical Dilemmas in Information Systems

**Privacy vs. Security**
Organizations must balance protecting individual privacy with ensuring security. For example:
- Should companies monitor employee emails and internet usage to prevent data breaches?
- Can governments access encrypted communications to prevent terrorism?
- Should organizations collect location data to improve services while risking privacy violations?

**Transparency vs. Competitive Advantage**
- Should companies disclose how their algorithms make decisions (e.g., credit scoring, hiring)?
- Must organizations reveal data collection practices that give them competitive advantages?
- Should source code be open or proprietary?

**Individual Rights vs. Collective Good**
- Should contact tracing apps collect personal data during pandemics?
- Can facial recognition be used for public safety despite privacy concerns?
- Should social media platforms censor misinformation even if it limits free speech?

**Innovation vs. Job Displacement**
- Should companies automate jobs even when it causes unemployment?
- What responsibility do organizations have to workers displaced by technology?
- How should benefits of automation be distributed?

## Information Rights and Obligations

### What Are Information Rights?

**Information rights** concern what information rights individuals and organizations possess with respect to information about themselves. Key questions include:
- What can they protect?
- What obligations do individuals and organizations have concerning this information?

### Privacy

**Privacy** is the claim of individuals to be left alone, free from surveillance or interference from other individuals or organizations, including the state. Privacy includes the right to control information about oneself.

### Fair Information Practices (FIP)

Most American and European privacy law is based on a regime called **Fair Information Practices (FIP)**, first set forth in a report written in 1973 by a federal government advisory committee.

**FIP Principles:**

1. **Notice/Awareness** - Websites must disclose their information practices before collecting data
2. **Choice/Consent** - Must be a choice regime in place allowing consumers to choose how their information will be used for secondary purposes other than supporting the transaction
3. **Access/Participation** - Consumers should be able to review and contest the accuracy and completeness of data collected about them
4. **Integrity/Security** - Data collectors must take responsible steps to assure that consumer information is accurate and secure from unauthorized use
5. **Enforcement/Redress** - Must be in place a mechanism to enforce FIP principles

### European Data Protection

In Europe, privacy protection is much more stringent than in the United States. Unlike the United States, European countries do not allow businesses to use personally identifiable information without consumers' prior consent.

**Key Concepts:**

**Informed Consent** - Consent given with knowledge of all the facts needed to make a rational decision.

**EU General Data Protection Regulation (GDPR)** - Provides comprehensive privacy protections including:
- Right to access personal data
- Right to be forgotten
- Right to data portability
- Requirements for explicit consent
- Mandatory breach notifications
- Significant penalties for violations

### Internet Challenges to Privacy

**Cookies**
Cookies are small text files deposited on a computer hard drive when a user visits websites. Cookies identify the visitor's Web browser software and track visits to the website. When the visitor returns to a site that has stored a cookie, the website software will search the visitor's computer, find the cookie, and know what that person has done in the past.

**Web Beacons**
Web beacons (also called web bugs) are tiny software programs that keep a hidden record of consumers' online clickstream and report this data back to whomever owns the tracking file invisibly embedded in e-mail messages and web pages that are designed to monitor the behavior of the user visiting a website or sending e-mail.

**Spyware**
Spyware can secretly install itself on an Internet user's computer by piggybacking on larger applications. Once installed, the spyware calls out to websites to send banner ads and other unsolicited material to the user, and it can report the user's movements on the Internet to other computers.

### Real-World Privacy Dilemmas

**Employee Monitoring**
- Should employers monitor employee emails, web browsing, and keystrokes?
- What level of monitoring is reasonable for productivity and security?
- Must employees be notified of monitoring?
- Where is the line between oversight and invasion of privacy?

**Customer Data Collection**
- How much customer data should companies collect?
- Should companies sell customer data to third parties?
- What happens to data when customers stop using a service?
- Should customers be able to opt out of data collection entirely?

**Surveillance Technology**
- Should cities deploy facial recognition cameras in public spaces?
- Can employers use biometric data (fingerprints, facial scans) for access control?
- Should schools monitor students through technology?
- What limits should exist on government surveillance?

**Health Data**
- Who owns medical records and health data?
- Should genetic information be shared with insurers or employers?
- Can health apps share data with third parties?
- What privacy protections should exist for mental health data?

## Property Rights and Obligations

### What Are Property Rights?

**Property rights** concern how traditional intellectual property rights will be protected in a digital society in which tracing and accounting for ownership are difficult and ignoring such property rights is so easy.

### Intellectual Property

**Intellectual property** is considered to be intangible property created by individuals or corporations. Information technology has made it difficult to protect intellectual property because computerized information can be so easily copied or distributed on networks.

### Types of Intellectual Property Protection

**Trade Secrets**
**Trade secrets** are any intellectual work product—a formula, device, pattern, or compilation of data—used for a business purpose that can be classified as belonging to that business, provided it is not based on information in the public domain.

**Examples:**
- Coca-Cola formula
- Google's search algorithm
- Customer lists and business processes
- Proprietary software code

**Copyright**
**Copyright** is a statutory grant that protects creators of intellectual property from having their work copied by others for any purpose during the life of the author plus an additional 70 years after the author's death. For corporate-owned works, copyright protection lasts for 95 years after their initial creation.

**Protected Works:**
- Literary works (books, articles, software code)
- Musical works
- Dramatic works
- Visual arts
- Motion pictures and audiovisual works
- Sound recordings

**Digital Millennium Copyright Act (DMCA)**
The Digital Millennium Copyright Act (DMCA) of 1998 also provides some copyright protection. The DMCA implements a World Intellectual Property Organization Treaty that makes it illegal to circumvent technology-based protections of copyrighted materials.

**Patents**
A **patent** grants the owner an exclusive monopoly on the ideas behind an invention for 20 years. The congressional intent behind patent law was to ensure that inventors of new machines, devices, or methods receive the full financial and other rewards of their labor and yet make widespread use of the invention possible by providing detailed diagrams for those wishing to use the idea under license from the patent's owner.

**Patent Requirements:**
- Must be novel (new)
- Must be non-obvious
- Must be useful
- Must be adequately described

**Patent Challenges in Software:**
The key concepts of patent law are originality, novelty, and invention. The Patent Office did not accept applications for software patents routinely until a 1981 Supreme Court decision that held that computer programs could be a part of a patentable process. Since that time, hundreds of patents have been granted and thousands await consideration.

### Real-World Property Rights Dilemmas

**Software Piracy**
- Is it ethical to use unlicensed software?
- Should students get free or discounted software?
- What responsibility do organizations have to prevent software piracy?
- How should software licenses be enforced?

**Digital Content Sharing**
- Is file sharing of music and movies theft or fair use?
- Should streaming services pay more to content creators?
- What rights do consumers have to content they purchase digitally?
- Can users resell digital goods they've purchased?

**Open Source vs. Proprietary**
- Should software be open source or proprietary?
- What obligations do users of open source software have?
- Can companies profit from open source software?
- How should contributions to open source projects be valued?

**Data Ownership**
- Who owns data generated by users on platforms?
- Can companies claim ownership of user-generated content?
- Should individuals be compensated for their data?
- What rights do users have to data they create?

**Artificial Intelligence and Copyright**
- Who owns content created by AI systems?
- Can AI-generated works be copyrighted?
- What happens when AI is trained on copyrighted material?
- Should AI developers compensate creators whose work trains AI?

**Patent Trolls**
- Should companies that don't produce products be able to hold patents?
- Are software patents too broad and stifling innovation?
- Should patent terms be shorter for rapidly evolving technologies?
- How can legitimate patent protection be balanced with innovation?

### Challenges in Digital Property Rights

**Easy Copying and Distribution**
Digital information can be copied perfectly and distributed globally at near-zero cost, making enforcement difficult.

**Global Jurisdiction**
The internet crosses national boundaries, creating conflicts between different legal systems and making enforcement challenging.

**Balancing Access and Protection**
Too much protection stifles innovation and access to knowledge; too little protection reduces incentives to create.

**Evolving Technology**
New technologies (streaming, cloud computing, AI) create situations not anticipated by existing laws.

## Ethical Analysis of Information and Property Rights Dilemmas

### Applying Ethical Principles

**Golden Rule**
- Would you want your privacy invaded this way?
- Would you want your creative work used without permission or compensation?

**Utilitarian Principle**
- Does collecting this data create more benefit than harm?
- Does strong copyright protection benefit society overall?

**Risk Aversion Principle**
- What are the worst-case scenarios of privacy violations?
- What harm could result from weak intellectual property protection?

**Kant's Categorical Imperative**
- Could universal privacy invasion be acceptable?
- Could society function if no one respected intellectual property?

### Balancing Competing Interests

**Privacy Decisions Must Balance:**
- Individual privacy rights vs. organizational needs
- Security requirements vs. civil liberties
- Innovation and personalization vs. data protection
- Transparency vs. competitive advantage

**Property Rights Decisions Must Balance:**
- Creator compensation vs. public access to knowledge
- Innovation incentives vs. freedom to build on existing work
- Individual rights vs. corporate interests
- Short-term profits vs. long-term societal benefit

## Summary

**Real-world ethical dilemmas** in information systems require careful analysis:
- Dilemmas often involve conflicts between competing values
- No single principle provides all answers
- Context and stakeholder impacts matter
- Professional judgment and ethical reasoning are essential

**Information rights** protect individual privacy and control over personal data:
- Fair Information Practices provide framework for privacy protection
- Technology makes privacy violations easier and more damaging
- Legal protections vary significantly across jurisdictions
- Balancing privacy with other values remains challenging

**Property rights** protect creators while enabling innovation:
- Multiple forms of protection (trade secrets, copyright, patents) serve different purposes
- Digital technology makes enforcement difficult
- Balancing protection with access is an ongoing challenge
- New technologies continually create new ethical and legal questions


# Accountability, Liability, System Quality, Quality of Life, and Health Risks

## Accountability

**Accountability** is a feature of systems and social institutions and means mechanisms are in place to determine who took responsible action, and who is responsible. Accountability refers to the structures and institutions that establish a link between actions and actors, making it a necessary condition of successful responsibility ascriptions.

### Accountability in Information Systems

While all employees of an organization are responsible for issues like cybersecurity, responsibility and accountability are not always equitably shared. In the corporate world, not every actor is blame-worthy, especially if the actor's autonomy is limited by structure, process, or circumstance. However, lack of autonomy is not an excuse for avoiding accountability entirely.

**Information security governance is the responsibility of the board of directors and senior executives**. The board is ultimately accountable to the shareholders for managing risk, including cybersecurity and privacy risk. That does not mean that the board will be doing the actual work—other people inside or outside of the organization will be responsible for that—but the board remains accountable.

### The CISO Role in Accountability

The CISO's role is to work with leadership to determine acceptable levels of risk for the organization. They are then accountable to the board for establishing and maintaining a corporate-wide information security management program to protect information assets.

The CISO position should be elevated and reported to the CEO or, even better, General Counsel to ensure independent operation. If an organization confines cybersecurity within the IT function, conflicts between operation progress and meeting risk management objectives are resolved at the CIO level, rather than the executive team or board where such decisions belong.

### Accountability vs. Responsibility

**Responsibility relates to completing a task, whereas accountability relates to the oversight and subsequent examination of its success, processes, and other consequences**. While all employees of the organization are responsible for cybersecurity, the accountable CEO may resign after the information system gets hacked.

## Liability

**Liability** is a feature of political systems in which a body of laws permits individuals and firms to recover damages to them by other actors, systems or organizations. Liability provides legal recourse when harm occurs.

### Liability in Information Systems

Determining liability and responsibility for software or hardware defects that can cause data breaches or other negative consequences is an ethical concern. Organizations must establish clear policies about who bears responsibility when systems fail or cause harm.

### Strengthened Liability Through Information Systems

With the extensive data collected and stored by information systems, it becomes easier to attribute liability in legal scenarios. In sectors like finance and healthcare, these systems allow organizations to maintain electronic records which make it simpler to identify discrepancies or fraud, holding individuals and businesses accountable for their actions.

### AI and Liability

**AI accountability inputs can assist in the development of liability regimes governing AI** by providing people and entities along the value chain with information and knowledge essential to assess legal risk and, as needed, exercise their rights. It can be difficult for those who have suffered AI-mediated employment discrimination, financial discrimination, or other AI system-related harms to bring a legal claim because proof, or even recognition, that an AI system led to harm can be hard to come by.

Accountability inputs can assist people harmed by AI to understand causal connections, and therefore help people determine whether to pursue legal or other remedies. At the same time, entities that may be on the other end of litigation (e.g., AI developers and deployers alleged to have caused or contributed to harm) can also benefit from more information flow about defensible processes.

### Legal Frameworks

Classic examples of emerging modern laws that increase legal liability risk are the EU General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA).

## System Quality

**System quality** concerns what standards of data and system quality we should demand to protect individual rights and the safety of society.

### Sources of Poor System Performance

Three principal sources of poor system performance are:
1. **Software bugs and errors** - Programming mistakes that cause systems to malfunction
2. **Hardware or facility failures** - Caused by natural disasters or other physical causes
3. **Poor input data quality** - Inaccurate, incomplete, or outdated data entering the system

### Vulnerability to System Errors

The doubling of computer power every 18 months has made it possible for most organizations to use information systems for their core production processes. As a result, our dependence on systems and our vulnerability to system errors and poor data quality have increased. Standards for ensuring the accuracy and reliability of information systems are not universally accepted or enforced.

### System Quality in Healthcare

**Methods that test or evaluate technology safety can be integrated into and used to prevent technology-induced errors**. Quality and safety professionals need to understand how errors propagate across a digital ecosystem of care, when technologies are integrated and interfaced across settings (e.g., from hospital to home).

Today's learning health system requires an understanding of digital health ecosystems that includes understanding how technologies have and can be used to re-engineer healthcare to remove error-prone processes and how these technologies can contribute to or introduce new types of errors.

### Quality Improvement Requirements

**Quality improvement requires five essential elements for success**:
1. Fostering and sustaining a culture of change and safety
2. Developing and clarifying an understanding of the problem
3. Involving key stakeholders
4. Testing change strategies
5. Continuous monitoring of performance and reporting of findings to sustain the change

### Proactive Risk Management

In 2001, the Joint Commission mandated that accredited health care providers conduct proactive risk management activities that identify and predict system weaknesses and adopt changes to minimize patient harm on one or two high-priority topics a year.

### Organizational Responsibilities

According to The Joint Commission, each accredited healthcare organization must:
- Ensure its leaders create and maintain a culture of safety and quality throughout the organization
- Function as a learning organization, requiring continuous education and improvement among personnel
- Encourage blame-free reporting of system and process failures
- Encourage proactive risk assessments by healthcare quality managers

## Quality of Life

**Quality of life** concerns what values should be preserved in an information and knowledge-based society, which institutions should we protect from violation, and which cultural values and practices are supported by the new information technology.

### Impact on Daily Life

Information systems have transformed everyday life through innovations in communication, education, and entertainment. These systems affect how we work, learn, communicate, and interact with society.

### Balancing Efficiency and Human Values

Any healthcare quality management that compromises service features essential for preserving person-centered care or patient-customer safety in the name of efficiency or cost reduction risks the customers' health and potentially worsens the quality and value of the service.

### Social and Cultural Implications

Information technology raises questions about:
- **Work-life balance** - Remote work capabilities blur boundaries between work and personal life
- **Social interaction** - Digital communication changes how people relate to each other
- **Privacy and autonomy** - Surveillance capabilities affect individual freedom
- **Digital divide** - Unequal access to technology creates social inequalities
- **Cultural values** - Technology may reinforce or challenge traditional values and practices

## Health Risks

Information systems and technology can pose various health risks to users and society.

### Physical Health Risks

**Computer Vision Syndrome (CVS)**
- Eye strain from prolonged screen time
- Headaches and blurred vision
- Dry eyes and discomfort

**Repetitive Stress Injuries (RSI)**
- Carpal tunnel syndrome from keyboard and mouse use
- Neck and back problems from poor posture
- Tendonitis and other musculoskeletal disorders

**Sedentary Lifestyle**
- Reduced physical activity from desk work
- Increased risk of obesity and cardiovascular disease
- Poor circulation and metabolic issues

### Mental Health Risks

**Stress and Burnout**
- Information overload and constant connectivity
- Pressure to respond immediately to communications
- Difficulty disconnecting from work

**Social Isolation**
- Reduced face-to-face interaction
- Dependence on digital communication
- Weakened social bonds and support networks

**Addiction**
- Compulsive use of social media and gaming
- Difficulty controlling technology use
- Negative impacts on relationships and productivity

### Safety Risks in Healthcare

The report "To Err Is Human: Building a Safer Health System" published by the United States Institute of Medicine highlighted that safety errors result in hundreds of thousands of deaths annually in the United States. Information systems can both help prevent and potentially contribute to these errors.

### Cybersecurity and Health

After 75 years into the computer age and after three ACM Turing Awards in the area of cryptography, we still do not seem to know how to build secure information systems. Security breaches in healthcare systems can expose sensitive patient data and potentially compromise patient safety.

## Summary

**Accountability** establishes mechanisms to identify who is responsible for actions and outcomes. The board is ultimately accountable to shareholders, while operational responsibility is distributed throughout the organization.

**Liability** provides legal frameworks for recovering damages when systems cause harm. Information systems make it easier to attribute liability through detailed record-keeping.

**System quality** addresses standards for data and system reliability to protect individual rights and societal safety. Quality improvement requires continuous monitoring, stakeholder involvement, and a culture of safety.

**Quality of life** concerns preserving human values in a technology-driven society. Organizations must balance efficiency with person-centered care and avoid compromising essential service features.

**Health risks** from information systems include physical ailments like repetitive stress injuries, mental health issues like stress and addiction, and safety concerns in critical systems like healthcare. Organizations must address these risks while leveraging technology's benefits.

